{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO78EKlIZVOE+HpLFRQqXop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhajagos/PHR2OHDSI/blob/main/Working_out_DQ_with_Mapped_Data_OHDSI_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdNi_FejEsu_"
      },
      "outputs": [],
      "source": [
        "%pip install pyspark==3.5.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Dz504H3sGNA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder\\\n",
        "    .config(\"spark.driver.memory\", \"16g\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "nwS1WqFRGWhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CDA_FILE_PATH = \"/content/drive/MyDrive/phr_ohdsi/source/jgh_documents/\"\n",
        "metadata_json = CDA_FILE_PATH + \"/output/ohdsi/ps_configuration.json.generated.parquet.json\""
      ],
      "metadata": {
        "id": "3L2O_4FxdB6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(metadata_json) as f:\n",
        "  metadata = json.load(f)"
      ],
      "metadata": {
        "id": "mLTj0NbjIHxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tables(sptr, metadata_dict, domains_to_load=[\"ohdsi\", \"concept\", \"prepared_source\"]):\n",
        "  sdf_dict = {}\n",
        "  for domain in domains_to_load:\n",
        "    print(f\"Loading domain: {domain}\")\n",
        "    for table in metadata_dict[domain]:\n",
        "      print(f\"Loading table: {table}\")\n",
        "      sdf_dict[table] = sptr.read.parquet(metadata_dict[domain][table])\n",
        "      sdf_dict[table].createOrReplaceTempView(table)\n",
        "  return sdf_dict"
      ],
      "metadata": {
        "id": "c6RfJOO2IKx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from types import MemberDescriptorType\n",
        "sdf_dict = load_tables(spark, metadata)"
      ],
      "metadata": {
        "id": "rOY2CBrQI0A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measurement table"
      ],
      "metadata": {
        "id": "5ZuVgXBavUIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meas_counts_df = spark.sql(\"\"\"\n",
        "select count(distinct person_id) as n, count(*) as n_r, measurement_concept_id, c.concept_name as measurement_concept_name,\n",
        "  min(value_as_number) as min_value_as_number, max(value_as_number) as max_value_as_number, c2.concept_code as unit_concept_code,\n",
        "  min(measurement_date) as min_measurement_date, max(measurement_date) as max_measurement_date, percentile(value_as_number, 0.25) as p25,\n",
        "  percentile(value_as_number, 0.5) as p50, percentile(value_as_number, 0.75) as p75\n",
        "  from measurement m join concept c on c.concept_id = m.measurement_concept_id\n",
        "left outer join concept c2 on c2.concept_id = m.unit_concept_id group by measurement_concept_id, c.concept_name, c2.concept_code order by count(1) desc\n",
        "\n",
        "\"\"\").toPandas()\n",
        "meas_counts_df"
      ],
      "metadata": {
        "id": "YhrpYtE-I5sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meas_counts_df[meas_counts_df.n_r >= 5]"
      ],
      "metadata": {
        "id": "FQUwF_BVz2Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select count(*), measurement_concept_id, measurement_concept_name, unit_source_value from (\n",
        "select m.measurement_concept_id,  c1.concept_name as measurement_concept_name, unit_source_value from measurement m\n",
        "join concept c1 on c1.concept_id = m.measurement_concept_id where unit_concept_id = 0\n",
        ") t group by measurement_concept_id, measurement_concept_name, unit_source_value order by count(*) desc\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "S5FX2AlSIZsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select m.measurement_concept_id, c1.concept_name as measurement_concept_name, value_source_value, unit_source_value from measurement m\n",
        "join concept c1 on c1.concept_id = m.measurement_concept_id where unit_concept_id = 0 and value_as_number is null limit 1000\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "z3to58KG3Qzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation"
      ],
      "metadata": {
        "id": "2H8IY93P9hFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select count(distinct person_id) as n, count(*) as n_r, observation_concept_id, concept_name,\n",
        "min(observation_date) as min_observation_date, max(observation_date) as max_observation_date\n",
        "from observation o\n",
        "join concept c on o.observation_concept_id = c.concept_id group by concept_name, observation_concept_id order by count(*) desc, min(observation_date) desc\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "0XdTx01s8uQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Condition Occcurrence"
      ],
      "metadata": {
        "id": "H9uo1ntV4mFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cond_df = spark.sql(\"\"\"\n",
        "select count(distinct person_id) as n, count(*) as n_r, condition_concept_id, c.concept_name as condition_concept_name,\n",
        "min(condition_start_date) as min_condition_date, max(coalesce(condition_end_date, condition_start_date)) as max_condition_date\n",
        " from condition_occurrence co\n",
        "  join concept c on c.concept_id = co.condition_concept_id\n",
        "  group by condition_concept_id, c.concept_name order by count(*) desc, min(condition_start_date) desc\"\"\").toPandas()\n",
        "cond_df"
      ],
      "metadata": {
        "id": "N8fxnL-yMAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drug Exposure"
      ],
      "metadata": {
        "id": "aRYgj85tAb3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select count(distinct person_id) as n, count(*) as n_r, drug_concept_id, c.concept_name  as drug_concept_name,\n",
        "min(drug_exposure_start_date) as min_drug_date, max(coalesce(drug_exposure_end_date, drug_exposure_start_date)) as max_drug_date\n",
        "from drug_exposure de join concept c on c.concept_id = de.drug_concept_id group by drug_concept_id, c.concept_name order by count(*) desc, min(drug_exposure_start_date) desc\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "cdM8PjMj75aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procedure Occurrence"
      ],
      "metadata": {
        "id": "7Sm73HMMApCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select count(distinct person_id) as n, count(*) as n_r, procedure_concept_id, c.concept_name as procedure_concept_name ,\n",
        "min(procedure_date) as min_procedure_date, max(procedure_date) as max_procedure_date\n",
        "from procedure_occurrence po\n",
        "join concept c on c.concept_id = po.procedure_concept_id\n",
        "group by procedure_concept_id, c.concept_name order by count(*) desc, min(procedure_date) desc\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "zRRXh08l_94p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Note"
      ],
      "metadata": {
        "id": "z5ZGIG9eveS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select s_note_class, count(*) as n_r from source_note group by s_note_class order by count(*) desc\").toPandas()"
      ],
      "metadata": {
        "id": "nBDjx6-CcRSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}